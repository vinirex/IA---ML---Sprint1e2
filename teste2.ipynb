{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308acc39",
   "metadata": {},
   "source": [
    "## Telemed - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb0bb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  quarter Bene_Geo_Desc Bene_Mdcd_Mdcr_Enrl_Stus Bene_Race_Desc  \\\n",
      "0  2020  Overall      National                      All            All   \n",
      "1  2020  Overall      National                      All            All   \n",
      "2  2020  Overall      National                      All            All   \n",
      "3  2020  Overall      National                      All            All   \n",
      "4  2020  Overall      National                      All            All   \n",
      "\n",
      "  Bene_Sex_Desc Bene_Mdcr_Entlmt_Stus Bene_Age_Desc Bene_RUCA_Desc  \\\n",
      "0           All                   All           All            All   \n",
      "1           All                   All           All          Rural   \n",
      "2           All                   All           All          Urban   \n",
      "3           All                   All           All        Unknown   \n",
      "4           All                   All          0-64            All   \n",
      "\n",
      "   Total_Bene_TH_Elig  Total_PartB_Enrl  Total_Bene_Telehealth  Pct_Telehealth  \n",
      "0          30946785.0      3.224489e+07             14826919.0          0.4791  \n",
      "1           7182616.0      7.493527e+06              2859483.0          0.3981  \n",
      "2          23699049.0      2.463142e+07             11945312.0          0.5040  \n",
      "3                 NaN               NaN                    NaN             NaN  \n",
      "4           4088345.0      4.291403e+06              2322324.0          0.5680  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31304 entries, 0 to 31303\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Year                      31304 non-null  int64  \n",
      " 1   quarter                   31304 non-null  object \n",
      " 2   Bene_Geo_Desc             31304 non-null  object \n",
      " 3   Bene_Mdcd_Mdcr_Enrl_Stus  31304 non-null  object \n",
      " 4   Bene_Race_Desc            31304 non-null  object \n",
      " 5   Bene_Sex_Desc             31304 non-null  object \n",
      " 6   Bene_Mdcr_Entlmt_Stus     31304 non-null  object \n",
      " 7   Bene_Age_Desc             31304 non-null  object \n",
      " 8   Bene_RUCA_Desc            31304 non-null  object \n",
      " 9   Total_Bene_TH_Elig        27990 non-null  float64\n",
      " 10  Total_PartB_Enrl          27990 non-null  float64\n",
      " 11  Total_Bene_Telehealth     27929 non-null  float64\n",
      " 12  Pct_Telehealth            27927 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 3.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_name = \"TMEDTREND_PUBLIC_250827.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# Inspect the data\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1e3f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Pct_Telehealth: 0.1776\n",
      "\n",
      "Unique values in quarter: 5\n",
      "quarter\n",
      "1          0.230565\n",
      "Overall    0.192645\n",
      "2          0.192287\n",
      "3          0.192287\n",
      "4          0.192215\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Geo_Desc: 55\n",
      "Bene_Geo_Desc\n",
      "National    0.098686\n",
      "Alabama     0.017689\n",
      "Alaska      0.017689\n",
      "Arizona     0.017689\n",
      "Arkansas    0.017689\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Race_Desc: 6\n",
      "Bene_Race_Desc\n",
      "All                       0.700111\n",
      "Black/African American    0.060515\n",
      "Non-Hispanic White        0.060515\n",
      "Hispanic                  0.060515\n",
      "Asian/Pacific Islander    0.060479\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Sex_Desc: 3\n",
      "Bene_Sex_Desc\n",
      "All       0.890142\n",
      "Female    0.054929\n",
      "Male      0.054929\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Age_Desc: 5\n",
      "Bene_Age_Desc\n",
      "All            0.780284\n",
      "0-64           0.054929\n",
      "65-74          0.054929\n",
      "75-84          0.054929\n",
      "85 and over    0.054929\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_RUCA_Desc: 3\n",
      "Bene_RUCA_Desc\n",
      "All      0.891073\n",
      "Urban    0.054929\n",
      "Rural    0.053998\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop rows with missing Pct_Telehealth\n",
    "df_clean = df.dropna(subset=['Pct_Telehealth']).copy()\n",
    "\n",
    "# 2. Create Binary Target Variable\n",
    "# Calculate the median of Pct_Telehealth\n",
    "median_telehealth = df_clean['Pct_Telehealth'].median()\n",
    "print(f\"Median Pct_Telehealth: {median_telehealth}\")\n",
    "\n",
    "# Create the binary target: 1 if Pct_Telehealth > median, 0 otherwise\n",
    "df_clean['High_Telehealth'] = (df_clean['Pct_Telehealth'] > median_telehealth).astype(int)\n",
    "\n",
    "# Drop the original 'Pct_Telehealth' and the aggregate count columns\n",
    "columns_to_drop = [\n",
    "    'Pct_Telehealth',\n",
    "    'Total_Bene_TH_Elig',\n",
    "    'Total_PartB_Enrl',\n",
    "    'Total_Bene_Telehealth',\n",
    "    'Bene_Mdcd_Mdcr_Enrl_Stus', # This column is mostly 'All' based on snippet, let's check unique values.\n",
    "    'Bene_Mdcr_Entlmt_Stus' # This column is mostly 'All' based on snippet, let's check unique values.\n",
    "]\n",
    "df_clean = df_clean.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Check unique values for key categorical columns before one-hot encoding\n",
    "categorical_cols = ['quarter', 'Bene_Geo_Desc', 'Bene_Race_Desc', 'Bene_Sex_Desc', 'Bene_Age_Desc', 'Bene_RUCA_Desc']\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nUnique values in {col}: {df_clean[col].nunique()}\")\n",
    "    print(df_clean[col].value_counts(normalize=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8093447905477981\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      2722\n",
      "           1       0.83      0.80      0.81      2864\n",
      "\n",
      "    accuracy                           0.81      5586\n",
      "   macro avg       0.81      0.81      0.81      5586\n",
      "weighted avg       0.81      0.81      0.81      5586\n",
      "\n",
      "\n",
      "First few columns of encoded features (X_encoded.head()):\n",
      "       Year  quarter_2  quarter_3  quarter_4  quarter_Overall  \\\n",
      "0 -1.407601      False      False      False             True   \n",
      "1 -1.407601      False      False      False             True   \n",
      "2 -1.407601      False      False      False             True   \n",
      "4 -1.407601      False      False      False             True   \n",
      "5 -1.407601      False      False      False             True   \n",
      "\n",
      "   Bene_Geo_Desc_Alaska  Bene_Geo_Desc_Arizona  Bene_Geo_Desc_Arkansas  \\\n",
      "0                 False                  False                   False   \n",
      "1                 False                  False                   False   \n",
      "2                 False                  False                   False   \n",
      "4                 False                  False                   False   \n",
      "5                 False                  False                   False   \n",
      "\n",
      "   Bene_Geo_Desc_California  Bene_Geo_Desc_Colorado  ...  \\\n",
      "0                     False                   False  ...   \n",
      "1                     False                   False  ...   \n",
      "2                     False                   False  ...   \n",
      "4                     False                   False  ...   \n",
      "5                     False                   False  ...   \n",
      "\n",
      "   Bene_Race_Desc_Hispanic  Bene_Race_Desc_Non-Hispanic White  \\\n",
      "0                    False                              False   \n",
      "1                    False                              False   \n",
      "2                    False                              False   \n",
      "4                    False                              False   \n",
      "5                    False                              False   \n",
      "\n",
      "   Bene_Sex_Desc_Female  Bene_Sex_Desc_Male  Bene_Age_Desc_65-74  \\\n",
      "0                 False               False                False   \n",
      "1                 False               False                False   \n",
      "2                 False               False                False   \n",
      "4                 False               False                False   \n",
      "5                 False               False                 True   \n",
      "\n",
      "   Bene_Age_Desc_75-84  Bene_Age_Desc_85 and over  Bene_Age_Desc_All  \\\n",
      "0                False                      False               True   \n",
      "1                False                      False               True   \n",
      "2                False                      False               True   \n",
      "4                False                      False              False   \n",
      "5                False                      False              False   \n",
      "\n",
      "   Bene_RUCA_Desc_Rural  Bene_RUCA_Desc_Urban  \n",
      "0                 False                 False  \n",
      "1                  True                 False  \n",
      "2                 False                  True  \n",
      "4                 False                 False  \n",
      "5                 False                 False  \n",
      "\n",
      "[5 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop('High_Telehealth', axis=1)\n",
    "y = df_clean['High_Telehealth']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "# Year is the only non-categorical, non-target column left\n",
    "numerical_cols = ['Year']\n",
    "\n",
    "# 1. One-Hot Encode Categorical Features\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Align the 'Year' column with the standardizer (even though it's just one column)\n",
    "# This step is often good practice if multiple numerical columns exist.\n",
    "scaler = StandardScaler()\n",
    "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train Logistic Regression Model\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict and Evaluate\n",
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Display the first few feature columns (post-encoding) for context\n",
    "print(\"\\nFirst few columns of encoded features (X_encoded.head()):\")\n",
    "print(X_encoded.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
