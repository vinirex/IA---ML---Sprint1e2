{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308acc39",
   "metadata": {},
   "source": [
    "## Telemed - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb0bb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  quarter Bene_Geo_Desc Bene_Mdcd_Mdcr_Enrl_Stus Bene_Race_Desc  \\\n",
      "0  2020  Overall      National                      All            All   \n",
      "1  2020  Overall      National                      All            All   \n",
      "2  2020  Overall      National                      All            All   \n",
      "3  2020  Overall      National                      All            All   \n",
      "4  2020  Overall      National                      All            All   \n",
      "\n",
      "  Bene_Sex_Desc Bene_Mdcr_Entlmt_Stus Bene_Age_Desc Bene_RUCA_Desc  \\\n",
      "0           All                   All           All            All   \n",
      "1           All                   All           All          Rural   \n",
      "2           All                   All           All          Urban   \n",
      "3           All                   All           All        Unknown   \n",
      "4           All                   All          0-64            All   \n",
      "\n",
      "   Total_Bene_TH_Elig  Total_PartB_Enrl  Total_Bene_Telehealth  Pct_Telehealth  \n",
      "0          30946785.0      3.224489e+07             14826919.0          0.4791  \n",
      "1           7182616.0      7.493527e+06              2859483.0          0.3981  \n",
      "2          23699049.0      2.463142e+07             11945312.0          0.5040  \n",
      "3                 NaN               NaN                    NaN             NaN  \n",
      "4           4088345.0      4.291403e+06              2322324.0          0.5680  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31304 entries, 0 to 31303\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Year                      31304 non-null  int64  \n",
      " 1   quarter                   31304 non-null  object \n",
      " 2   Bene_Geo_Desc             31304 non-null  object \n",
      " 3   Bene_Mdcd_Mdcr_Enrl_Stus  31304 non-null  object \n",
      " 4   Bene_Race_Desc            31304 non-null  object \n",
      " 5   Bene_Sex_Desc             31304 non-null  object \n",
      " 6   Bene_Mdcr_Entlmt_Stus     31304 non-null  object \n",
      " 7   Bene_Age_Desc             31304 non-null  object \n",
      " 8   Bene_RUCA_Desc            31304 non-null  object \n",
      " 9   Total_Bene_TH_Elig        27990 non-null  float64\n",
      " 10  Total_PartB_Enrl          27990 non-null  float64\n",
      " 11  Total_Bene_Telehealth     27929 non-null  float64\n",
      " 12  Pct_Telehealth            27927 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 3.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_name = \"TMEDTREND_PUBLIC_250827.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# Inspect the data\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1e3f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Pct_Telehealth: 0.1776\n",
      "\n",
      "Unique values in quarter: 5\n",
      "quarter\n",
      "1          0.230565\n",
      "Overall    0.192645\n",
      "2          0.192287\n",
      "3          0.192287\n",
      "4          0.192215\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Geo_Desc: 55\n",
      "Bene_Geo_Desc\n",
      "National    0.098686\n",
      "Alabama     0.017689\n",
      "Alaska      0.017689\n",
      "Arizona     0.017689\n",
      "Arkansas    0.017689\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Race_Desc: 6\n",
      "Bene_Race_Desc\n",
      "All                       0.700111\n",
      "Black/African American    0.060515\n",
      "Non-Hispanic White        0.060515\n",
      "Hispanic                  0.060515\n",
      "Asian/Pacific Islander    0.060479\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Sex_Desc: 3\n",
      "Bene_Sex_Desc\n",
      "All       0.890142\n",
      "Female    0.054929\n",
      "Male      0.054929\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_Age_Desc: 5\n",
      "Bene_Age_Desc\n",
      "All            0.780284\n",
      "0-64           0.054929\n",
      "65-74          0.054929\n",
      "75-84          0.054929\n",
      "85 and over    0.054929\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Unique values in Bene_RUCA_Desc: 3\n",
      "Bene_RUCA_Desc\n",
      "All      0.891073\n",
      "Urban    0.054929\n",
      "Rural    0.053998\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop rows with missing Pct_Telehealth\n",
    "df_clean = df.dropna(subset=['Pct_Telehealth']).copy()\n",
    "\n",
    "# 2. Create Binary Target Variable\n",
    "# Calculate the median of Pct_Telehealth\n",
    "median_telehealth = df_clean['Pct_Telehealth'].median()\n",
    "print(f\"Median Pct_Telehealth: {median_telehealth}\")\n",
    "\n",
    "# Create the binary target: 1 if Pct_Telehealth > median, 0 otherwise\n",
    "df_clean['High_Telehealth'] = (df_clean['Pct_Telehealth'] > median_telehealth).astype(int)\n",
    "\n",
    "# Drop the original 'Pct_Telehealth' and the aggregate count columns\n",
    "columns_to_drop = [\n",
    "    'Pct_Telehealth',\n",
    "    'Total_Bene_TH_Elig',\n",
    "    'Total_PartB_Enrl',\n",
    "    'Total_Bene_Telehealth',\n",
    "    'Bene_Mdcd_Mdcr_Enrl_Stus', # This column is mostly 'All' based on snippet, let's check unique values.\n",
    "    'Bene_Mdcr_Entlmt_Stus' # This column is mostly 'All' based on snippet, let's check unique values.\n",
    "]\n",
    "df_clean = df_clean.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Check unique values for key categorical columns before one-hot encoding\n",
    "categorical_cols = ['quarter', 'Bene_Geo_Desc', 'Bene_Race_Desc', 'Bene_Sex_Desc', 'Bene_Age_Desc', 'Bene_RUCA_Desc']\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nUnique values in {col}: {df_clean[col].nunique()}\")\n",
    "    print(df_clean[col].value_counts(normalize=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8093447905477981\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81      2722\n",
      "           1       0.83      0.80      0.81      2864\n",
      "\n",
      "    accuracy                           0.81      5586\n",
      "   macro avg       0.81      0.81      0.81      5586\n",
      "weighted avg       0.81      0.81      0.81      5586\n",
      "\n",
      "\n",
      "First few columns of encoded features (X_encoded.head()):\n",
      "       Year  quarter_2  quarter_3  quarter_4  quarter_Overall  \\\n",
      "0 -1.407601      False      False      False             True   \n",
      "1 -1.407601      False      False      False             True   \n",
      "2 -1.407601      False      False      False             True   \n",
      "4 -1.407601      False      False      False             True   \n",
      "5 -1.407601      False      False      False             True   \n",
      "\n",
      "   Bene_Geo_Desc_Alaska  Bene_Geo_Desc_Arizona  Bene_Geo_Desc_Arkansas  \\\n",
      "0                 False                  False                   False   \n",
      "1                 False                  False                   False   \n",
      "2                 False                  False                   False   \n",
      "4                 False                  False                   False   \n",
      "5                 False                  False                   False   \n",
      "\n",
      "   Bene_Geo_Desc_California  Bene_Geo_Desc_Colorado  ...  \\\n",
      "0                     False                   False  ...   \n",
      "1                     False                   False  ...   \n",
      "2                     False                   False  ...   \n",
      "4                     False                   False  ...   \n",
      "5                     False                   False  ...   \n",
      "\n",
      "   Bene_Race_Desc_Hispanic  Bene_Race_Desc_Non-Hispanic White  \\\n",
      "0                    False                              False   \n",
      "1                    False                              False   \n",
      "2                    False                              False   \n",
      "4                    False                              False   \n",
      "5                    False                              False   \n",
      "\n",
      "   Bene_Sex_Desc_Female  Bene_Sex_Desc_Male  Bene_Age_Desc_65-74  \\\n",
      "0                 False               False                False   \n",
      "1                 False               False                False   \n",
      "2                 False               False                False   \n",
      "4                 False               False                False   \n",
      "5                 False               False                 True   \n",
      "\n",
      "   Bene_Age_Desc_75-84  Bene_Age_Desc_85 and over  Bene_Age_Desc_All  \\\n",
      "0                False                      False               True   \n",
      "1                False                      False               True   \n",
      "2                False                      False               True   \n",
      "4                False                      False              False   \n",
      "5                False                      False              False   \n",
      "\n",
      "   Bene_RUCA_Desc_Rural  Bene_RUCA_Desc_Urban  \n",
      "0                 False                 False  \n",
      "1                  True                 False  \n",
      "2                 False                  True  \n",
      "4                 False                 False  \n",
      "5                 False                 False  \n",
      "\n",
      "[5 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop('High_Telehealth', axis=1)\n",
    "y = df_clean['High_Telehealth']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "# Year is the only non-categorical, non-target column left\n",
    "numerical_cols = ['Year']\n",
    "\n",
    "# 1. One-Hot Encode Categorical Features\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Align the 'Year' column with the standardizer (even though it's just one column)\n",
    "# This step is often good practice if multiple numerical columns exist.\n",
    "scaler = StandardScaler()\n",
    "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train Logistic Regression Model\n",
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict and Evaluate\n",
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Display the first few feature columns (post-encoding) for context\n",
    "print(\"\\nFirst few columns of encoded features (X_encoded.head()):\")\n",
    "print(X_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88925b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinicius.silva\\AppData\\Local\\Temp\\ipykernel_21108\\3019787255.py:40: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Coefficient', y='Feature', data=top_features, palette='vlag')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix and feature coefficients plot saved.\n",
      "Number of features in the encoded dataset: 72\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Assuming log_reg, X_encoded, y_test, y_pred are available from previous context\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Low Telehealth (0)', 'High Telehealth (1)'],\n",
    "            yticklabels=['Low Telehealth (0)', 'High Telehealth (1)'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Telehealth Classification')\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Feature Coefficients Graph\n",
    "# Get coefficients and feature names\n",
    "coefficients = log_reg.coef_[0]\n",
    "feature_names = X_encoded.columns\n",
    "\n",
    "# Combine, sort by magnitude, and select top/bottom features\n",
    "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "coef_df['Abs_Coefficient'] = np.abs(coef_df['Coefficient'])\n",
    "coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False).drop(columns='Abs_Coefficient')\n",
    "\n",
    "# Select the top 15 features by magnitude\n",
    "top_n = 15\n",
    "top_features = pd.concat([coef_df.head(top_n // 2), coef_df.tail(top_n // 2)]).sort_values(by='Coefficient', ascending=False)\n",
    "if len(coef_df) >= top_n:\n",
    "    top_features = coef_df.iloc[:top_n].sort_values(by='Coefficient', ascending=False)\n",
    "else:\n",
    "    # If there are fewer than 15 features, just plot all of them\n",
    "    top_features = coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=top_features, palette='vlag')\n",
    "plt.title(f'Top {len(top_features)} Logistic Regression Coefficients')\n",
    "plt.xlabel('Coefficient Value (Influence on Log Odds of High Telehealth)')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_coefficients.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Confusion matrix and feature coefficients plot saved.\")\n",
    "\n",
    "# 3. Correlation Matrix Calculation (preparation for explanation)\n",
    "# Due to the large number of features (many from one-hot encoding), \n",
    "# the full correlation matrix is huge (76x76). I will calculate it,\n",
    "# but only print the number of features and explain the nature of correlation in OHE data.\n",
    "correlation_matrix = X_encoded.corr()\n",
    "print(f\"Number of features in the encoded dataset: {len(X_encoded.columns)}\")\n",
    "\n",
    "# I will save a small, representative subset to CSV for user, perhaps focusing on the 'Year' and a few key geo/demographic features.\n",
    "# Let's select 'Year' and the first 10 OHE columns for a snippet.\n",
    "# feature_subset = X_encoded.columns[:11]\n",
    "# subset_corr_matrix = X_encoded[feature_subset].corr()\n",
    "# subset_corr_matrix.to_csv(\"subset_correlation_matrix.csv\")\n",
    "# I will proceed with the explanation without saving a matrix as it is unlikely to be very informative in this case, but I will write the explanation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
